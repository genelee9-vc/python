{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\g_lee\\\\Python Practice'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='price.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00_Practice_with_SimpleExpressions_Arithmetic.ipynb',\n",
       " '01_Practice_Py_Code.ipynb',\n",
       " '02_Practice_with_Lists.ipynb',\n",
       " '03_Practice_with_Tuples.ipynb',\n",
       " '04_Practice_with_Dictionaries.ipynb',\n",
       " '05_Practice_with_If_Statements.ipynb',\n",
       " '06_Practice_with_ForLoops.ipynb',\n",
       " '07_Practice_with_WhileLoops.ipynb',\n",
       " '08_Practice_with_BreakContinuePass.ipynb',\n",
       " '09_Practice_with_FunctionsInputsArgumentsReturnValues.ipynb',\n",
       " '10_Practice_with_Functions_Continued.ipynb',\n",
       " '11_Practice_with_ImportingModules.ipynb',\n",
       " '12_Practice_with_CommandLineAndEnvironVariables.ipynb',\n",
       " '13_Practice_with_Files.ipynb',\n",
       " 'BasicTypesInPython.ipynb',\n",
       " 'IRIS.csv',\n",
       " 'myscript.py',\n",
       " 'newfile.py',\n",
       " 'price.csv',\n",
       " 'price.py',\n",
       " 'saved_iris_df.csv',\n",
       " 'sin_curve.ipynb',\n",
       " 'Strings.ipynb',\n",
       " 'UnderstandingJupyter.ipynb',\n",
       " 'UnderstandingJupyterPy3.ipynb',\n",
       " 'Variables.ipynb',\n",
       " 'WorkingWithJupyterNotebooks.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='price.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('price.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Things,Quantity,Total_Price\\nSpoon,105.0,1050\\nPlate,78.0,2250\\nCup,90.0,1550\\nFork,NaN,890\\nBread,21.0,620\\nJuice,85.0,2125\\nBiscuit,15.0,312\\nCake,18.0,523\\nChocolate,100.0,100'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILE handle acts as a pointer to the file\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the pointer already read the file, it has nothing else to read since it is \"at the end\"\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The \"SEEK\" commnand points the file handle back to the very first byte position in the file, or zero (0)\n",
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Things,Quantity,Total_Price\\nSpoon,105.0,1050\\nPlate,78.0,2250\\nCup,90.0,1550\\nFork,NaN,890\\nBread,21.0,620\\nJuice,85.0,2125\\nBiscuit,15.0,312\\nCake,18.0,523\\nChocolate,100.0,100'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thing'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just want to read the first 5 bytes\n",
    "file.read(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s,Quan'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will read 6 bytes, starting at the 5th byte\n",
    "file.read(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TELL reveals the byte position that the READ command is\n",
    "file.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tity,Total_Price\\nSpoon,105.0,1050\\nPlate,78.0,2250\\nCup,90.0,1550\\nFork,NaN,890\\nBread,21.0,620\\nJuice,85.0,2125\\nBiscuit,15.0,312\\nCake,18.0,523\\nChocolate,100.0,100'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After opening a file, you need to close it to prevent corruption\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f3fc120c03c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='price.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('price.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Things,Quantity,Total_Price\\nSpoon,105.0,1050\\nPlate,78.0,2250\\nCup,90.0,1550\\nFork,NaN,890\\nBread,21.0,620\\nJuice,85.0,2125\\nBiscuit,15.0,312\\nCake,18.0,523\\nChocolate,100.0,100'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Things,Quantity,Total_Price\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READLINE reads the file one line at a time\n",
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spoon,105.0,1050\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plate,78.0,2250\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cup,90.0,1550\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Things,Quantity,Total_Price\\n',\n",
       " 'Spoon,105.0,1050\\n',\n",
       " 'Plate,78.0,2250\\n',\n",
       " 'Cup,90.0,1550\\n',\n",
       " 'Fork,NaN,890\\n',\n",
       " 'Bread,21.0,620\\n',\n",
       " 'Juice,85.0,2125\\n',\n",
       " 'Biscuit,15.0,312\\n',\n",
       " 'Cake,18.0,523\\n',\n",
       " 'Chocolate,100.0,100']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Readlines returns all the lines in your file in the form of a py List\n",
    "file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f3fc120c03c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number or characters: 5\n"
     ]
    }
   ],
   "source": [
    "#\"a\" appends to existing file\n",
    "with open('IRIS.csv', 'a') as f:\n",
    "    more_flowers = f.write(\"Roses\")\n",
    "    \n",
    "    print(\"Number or characters:\",more_flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f3fc120c03c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='IRIS.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('IRIS.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sepal_length,sepal_width,petal_length,petal_width,species\\n5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-setosa\\n4.7,3.2,1.3,0.2,Iris-setosa\\n4.6,3.1,1.5,0.2,Iris-setosa\\n5.0,3.6,1.4,0.2,Iris-setosa\\n5.0,3.5,1.5,0.2,Iris-setosaRoses'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length,sepal_width,petal_length,petal_width,species\\n',\n",
       " '5.1,3.5,1.4,0.2,Iris-setosa\\n',\n",
       " '4.9,3.0,1.4,0.2,Iris-setosa\\n',\n",
       " '4.7,3.2,1.3,0.2,Iris-setosa\\n',\n",
       " '4.6,3.1,1.5,0.2,Iris-setosa\\n',\n",
       " '5.0,3.6,1.4,0.2,Iris-setosa\\n',\n",
       " '5.0,3.5,1.5,0.2,Iris-setosaRoses']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sportscars.txt\",'w') as f:\n",
    "    f.write(\"Mustang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat sportscars.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='sportscars.txt' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('sportscars.txt')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mustang'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_cars = ['Agera','Regera','Chiron','Veyron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sportscars.txt','w') as f:\n",
    "    for car in sports_cars:\n",
    "        f.write(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AgeraRegeraChironVeyron'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding breaks\n",
    "with open('sportscars.txt','w') as f:\n",
    "    for car in sports_cars:\n",
    "        f.write(car + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agera\\nRegera\\nChiron\\nVeyron\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agera\\n', 'Regera\\n', 'Chiron\\n', 'Veyron\\n']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\g_lee\\\\Python Practice'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00_Practice_with_SimpleExpressions_Arithmetic.ipynb',\n",
       " '01_Practice_Py_Code.ipynb',\n",
       " '02_Practice_with_Lists.ipynb',\n",
       " '03_Practice_with_Tuples.ipynb',\n",
       " '04_Practice_with_Dictionaries.ipynb',\n",
       " '05_Practice_with_If_Statements.ipynb',\n",
       " '06_Practice_with_ForLoops.ipynb',\n",
       " '07_Practice_with_WhileLoops.ipynb',\n",
       " '08_Practice_with_BreakContinuePass.ipynb',\n",
       " '09_Practice_with_FunctionsInputsArgumentsReturnValues.ipynb',\n",
       " '10_Practice_with_Functions_Continued.ipynb',\n",
       " '11_Practice_with_ImportingModules.ipynb',\n",
       " '12_Practice_with_CommandLineAndEnvironVariables.ipynb',\n",
       " '13_Practice_with_Files.ipynb',\n",
       " 'BasicTypesInPython.ipynb',\n",
       " 'IRIS.csv',\n",
       " 'myscript.py',\n",
       " 'newfile.py',\n",
       " 'price.csv',\n",
       " 'price.py',\n",
       " 'saved_iris_df.csv',\n",
       " 'sin_curve.ipynb',\n",
       " 'sportscars.txt',\n",
       " 'Strings.ipynb',\n",
       " 'UnderstandingJupyter.ipynb',\n",
       " 'UnderstandingJupyterPy3.ipynb',\n",
       " 'Variables.ipynb',\n",
       " 'WorkingWithJupyterNotebooks.ipynb']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Things', 'Quantity', 'Total_Price']\n",
      "['Spoon', '105.0', '1050']\n",
      "['Plate', '78.0', '2250']\n",
      "['Cup', '90.0', '1550']\n",
      "['Fork', 'NaN', '890']\n",
      "['Bread', '21.0', '620']\n",
      "['Juice', '85.0', '2125']\n",
      "['Biscuit', '15.0', '312']\n",
      "['Cake', '18.0', '523']\n",
      "['Chocolate', '100.0', '100']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open (\"price.csv\",'r') as f:\n",
    "    csv_reader=csv.reader(f)\n",
    "    for price in csv_reader:\n",
    "        print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Things', 'Spoon'), ('Quantity', '105.0'), ('Total_Price', '1050')])\n",
      "OrderedDict([('Things', 'Plate'), ('Quantity', '78.0'), ('Total_Price', '2250')])\n",
      "OrderedDict([('Things', 'Cup'), ('Quantity', '90.0'), ('Total_Price', '1550')])\n",
      "OrderedDict([('Things', 'Fork'), ('Quantity', 'NaN'), ('Total_Price', '890')])\n",
      "OrderedDict([('Things', 'Bread'), ('Quantity', '21.0'), ('Total_Price', '620')])\n",
      "OrderedDict([('Things', 'Juice'), ('Quantity', '85.0'), ('Total_Price', '2125')])\n",
      "OrderedDict([('Things', 'Biscuit'), ('Quantity', '15.0'), ('Total_Price', '312')])\n",
      "OrderedDict([('Things', 'Cake'), ('Quantity', '18.0'), ('Total_Price', '523')])\n",
      "OrderedDict([('Things', 'Chocolate'), ('Quantity', '100.0'), ('Total_Price', '100')])\n"
     ]
    }
   ],
   "source": [
    "#If csv file has headings use DictReader to parse into tuples\n",
    "\n",
    "with open (\"price.csv\",'r') as f:\n",
    "    csv_reader=csv.DictReader(f)\n",
    "    for price in csv_reader:\n",
    "        print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas still the best python library to use with CSV files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Things</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spoon</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plate</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cup</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fork</td>\n",
       "      <td>NaN</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bread</td>\n",
       "      <td>21.0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Juice</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Biscuit</td>\n",
       "      <td>15.0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cake</td>\n",
       "      <td>18.0</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chocolate</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Things  Quantity  Total_Price\n",
       "0      Spoon     105.0         1050\n",
       "1      Plate      78.0         2250\n",
       "2        Cup      90.0         1550\n",
       "3       Fork       NaN          890\n",
       "4      Bread      21.0          620\n",
       "5      Juice      85.0         2125\n",
       "6    Biscuit      15.0          312\n",
       "7       Cake      18.0          523\n",
       "8  Chocolate     100.0          100"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contents of csv will be read as a dataframe with the headings parsed above the line\n",
    "df = pd.read_csv('price.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oba': 8.9, 'Moje': 4.5, 'Nemo': 1.25}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs_and_ages = {\"Oba\":8.9,\n",
    "                \"Moje\":4.5,\n",
    "                \"Nemo\":1.25}\n",
    "dogs_and_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Oba\": 8.9, \"Moje\": 4.5, \"Nemo\": 1.25}'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converts dictionary to JSON string\n",
    "json_string = json.dumps(dogs_and_ages)\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use this function to convert JSON data into Python Dictionary (Step 1\n",
    "dogs_and_ages_string = \"\"\"\n",
    "{\"Oba\": 8.9, \"Moje\": 4.5, \"Nemo\": 1.25}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oba': 8.9, 'Moje': 4.5, 'Nemo': 1.25}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2 converting JSON string into python dictionary\n",
    "dogs_and_ages_dict = json.loads(dogs_and_ages_string)\n",
    "dogs_and_ages_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dogs_and_ages_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating JSON file using DUMP command\n",
    "with open(\"dogs_and_ages.json\",'w') as dog_file:\n",
    "    json.dump(dogs_and_ages_dict,dog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00_Practice_with_SimpleExpressions_Arithmetic.ipynb',\n",
       " '01_Practice_Py_Code.ipynb',\n",
       " '02_Practice_with_Lists.ipynb',\n",
       " '03_Practice_with_Tuples.ipynb',\n",
       " '04_Practice_with_Dictionaries.ipynb',\n",
       " '05_Practice_with_If_Statements.ipynb',\n",
       " '06_Practice_with_ForLoops.ipynb',\n",
       " '07_Practice_with_WhileLoops.ipynb',\n",
       " '08_Practice_with_BreakContinuePass.ipynb',\n",
       " '09_Practice_with_FunctionsInputsArgumentsReturnValues.ipynb',\n",
       " '10_Practice_with_Functions_Continued.ipynb',\n",
       " '11_Practice_with_ImportingModules.ipynb',\n",
       " '12_Practice_with_CommandLineAndEnvironVariables.ipynb',\n",
       " '13_Practice_with_Files.ipynb',\n",
       " 'BasicTypesInPython.ipynb',\n",
       " 'dogs_and_ages.json',\n",
       " 'IRIS.csv',\n",
       " 'myscript.py',\n",
       " 'newfile.py',\n",
       " 'price.csv',\n",
       " 'price.py',\n",
       " 'saved_iris_df.csv',\n",
       " 'sin_curve.ipynb',\n",
       " 'sportscars.txt',\n",
       " 'Strings.ipynb',\n",
       " 'UnderstandingJupyter.ipynb',\n",
       " 'UnderstandingJupyterPy3.ipynb',\n",
       " 'Variables.ipynb',\n",
       " 'WorkingWithJupyterNotebooks.ipynb']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='dogs_and_ages.json' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('dogs_and_ages.json')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Oba\": 8.9, \"Moje\": 4.5, \"Nemo\": 1.25}'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also read the JSON file this way\n",
    "with open ('dogs_and_ages.json','r') as dog_file:\n",
    "    file_json = json.load(dog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oba': 8.9, 'Moje': 4.5, 'Nemo': 1.25}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.6.1\n",
      "jupyter-notebook : 6.0.3\n",
      "qtconsole        : 4.6.0\n",
      "ipython          : 7.12.0\n",
      "ipykernel        : 5.1.4\n",
      "jupyter client   : 5.3.4\n",
      "jupyter lab      : 1.2.6\n",
      "nbconvert        : 5.6.1\n",
      "ipywidgets       : 7.5.1\n",
      "nbformat         : 5.0.4\n",
      "traitlets        : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.6.3\n",
      "jupyter-notebook : 6.0.3\n",
      "qtconsole        : 4.7.3\n",
      "ipython          : 7.13.0\n",
      "ipykernel        : 5.2.1\n",
      "jupyter client   : 6.1.3\n",
      "jupyter lab      : 2.1.1\n",
      "nbconvert        : 5.6.1\n",
      "ipywidgets       : 7.5.1\n",
      "nbformat         : 5.0.6\n",
      "traitlets        : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4de4eff19ade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_array' is not defined"
     ]
    }
   ],
   "source": [
    "dir(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_array = np.array([0,0,7])\n",
    "type(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 5.],\n",
       "       [8., 1., 4.],\n",
       "       [7., 3., 9.],\n",
       "       [2., 0., 7.],\n",
       "       [4., 5., 8.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use \"Delimiter\" command to load files that were not created by Numpy code\n",
    "gene_np = np.loadtxt('Data_Files\\gene.txt',delimiter=',')\n",
    "gene_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 5.],\n",
       "       [8., 4.],\n",
       "       [7., 9.],\n",
       "       [2., 7.],\n",
       "       [4., 8.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To specify certain columns to load rather than the whole file. This example is only loading the first (0) and last(2) columns\n",
    "gene_np = np.loadtxt('Data_Files/gene.txt',delimiter=',',usecols=(0,2))\n",
    "gene_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Agera'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-af23c4f1b769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use \"Delimiter\" command to load files that were not created by Numpy code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msportscars_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data_Files\\sportscars.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msportscars_np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Agera'"
     ]
    }
   ],
   "source": [
    "# This causes an error b/c there are string values in the file where integers are expected\n",
    "sportscars_np = np.loadtxt('Data_Files\\sportscars.txt',delimiter=',')\n",
    "sportscars_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  400., 75000.],\n",
       "       [  560., 49000.],\n",
       "       [  365., 39875.],\n",
       "       [  411., 86000.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usecols command allows you to bypass string values in a column\n",
    "sportscars_np = np.loadtxt('Data_Files\\sportscars.txt',delimiter=',',usecols=(1,2))\n",
    "sportscars_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aeeac2dd6648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# What if they're in your header now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgene_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data_Files\\gene.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgene_np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g_lee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ID'"
     ]
    }
   ],
   "source": [
    "# What if they're in your header now\n",
    "gene_np = np.loadtxt('Data_Files\\gene.txt',delimiter=',')\n",
    "gene_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 5.],\n",
       "       [8., 1., 4.],\n",
       "       [7., 3., 9.],\n",
       "       [2., 0., 7.],\n",
       "       [4., 5., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use \"skiprows\". Can also use \"skipfooter\" if there is data to be left out at the end of the file\n",
    "gene_np = np.loadtxt('Data_Files\\gene.txt',delimiter=',',skiprows=1)\n",
    "gene_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.,   4.,   5.],\n",
       "       [108.,   1.,   4.],\n",
       "       [107.,   3.,   9.],\n",
       "       [102.,   0.,   7.],\n",
       "       [104.,   5.,   8.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert option\n",
    "def increase(the_ID):\n",
    "    return int(the_ID) + 100\n",
    "\n",
    "gene_increase = np.loadtxt('Data_Files\\gene.txt',delimiter=',',skiprows=1,\n",
    "                          converters={0:increase})\n",
    "gene_increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [ 0.,  4.,  5.],\n",
       "       [ 8.,  1.,  4.],\n",
       "       [ 7.,  3.,  9.],\n",
       "       [ 2.,  0., nan],\n",
       "       [ 4.,  5.,  8.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy \"genfromtext\" function replaces missing or non-numerical values with 'nan' or 'not a number'\n",
    "gene_missing_value = np.genfromtxt('Data_Files/gene_missing.txt',\n",
    "                                   delimiter=',')\n",
    "gene_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  4.,  5.],\n",
       "       [ 8.,  1.,  4.],\n",
       "       [ 7.,  3.,  9.],\n",
       "       [ 2.,  0., nan],\n",
       "       [ 4.,  5.,  8.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to avoid nan values in first row, use 'skip_header' function\n",
    "gene_missing_value = np.genfromtxt('Data_Files/gene_missing.txt',\n",
    "                                   delimiter=',',skip_header=1)\n",
    "gene_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Python CSV library implements classes to read (and write) tabular data in csv format\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dialect',\n",
       " 'DictReader',\n",
       " 'DictWriter',\n",
       " 'Error',\n",
       " 'QUOTE_ALL',\n",
       " 'QUOTE_MINIMAL',\n",
       " 'QUOTE_NONE',\n",
       " 'QUOTE_NONNUMERIC',\n",
       " 'Sniffer',\n",
       " 'StringIO',\n",
       " '_Dialect',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'excel',\n",
       " 'excel_tab',\n",
       " 'field_size_limit',\n",
       " 'get_dialect',\n",
       " 'list_dialects',\n",
       " 're',\n",
       " 'reader',\n",
       " 'register_dialect',\n",
       " 'unix_dialect',\n",
       " 'unregister_dialect',\n",
       " 'writer']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excel-tab', 'excel']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.list_dialects()\n",
    "['excel-tab','excel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['68.95', '35', '61833.9', '256.09', 'Cloned 5thgeneration orchestration', 'Wrightburgh', '0', 'Tunisia', '3/27/2016 0:53', '0']\n",
      "['80.23', '31', '68441.85', '193.77', 'Monitored national standardization', 'West Jodi', '1', 'Nauru', '4/4/2016 1:39', '0']\n",
      "['69.47', '26', '59785.94', '236.5', 'Organic bottom-line service-desk', 'Davidton', '0', 'San Marino', '3/13/2016 20:35', '0']\n",
      "['74.15', '29', '54806.18', '245.89', 'Triple-buffered reciprocal time-frame', 'West Terrifurt', '1', 'Italy', '1/10/2016 2:31', '0']\n",
      "['68.37', '35', '73889.99', '225.58', 'Robust logistical utilization', 'South Manuel', '0', 'Iceland', '6/3/2016 3:36', '0']\n",
      "['59.99', '23', '59761.56', '226.74', 'Sharable client-driven software', 'Jamieberg', '1', 'Norway', '5/19/2016 14:30', '0']\n",
      "['88.91', '33', '53852.85', '208.36', 'Enhanced dedicated support', 'Brandonstad', '0', 'Myanmar', '1/28/2016 20:59', '0']\n",
      "['66', '48', '24593.33', '131.76', 'Reactive local challenge', 'Port Jefferybury', '1', 'Australia', '3/7/2016 1:40', '1']\n",
      "['74.53', '30', '68862', '221.51', 'Configurable coherent function', 'West Colin', '1', 'Grenada', '4/18/2016 9:33', '0']\n",
      "['69.88', '20', '55642.32', '183.82', 'Mandatory homogeneous architecture', 'Ramirezton', '1', 'Ghana', '7/11/2016 1:42', '0']\n",
      "['47.64', '49', '45632.51', '122.02', 'Centralized neutral neural-net', 'West Brandonton', '0', 'Qatar', '3/16/2016 20:19', '1']\n",
      "['83.07', '37', '62491.01', '230.87', 'Team-oriented grid-enabled Local Area Network', 'East Theresashire', '1', 'Burundi', '5/8/2016 8:10', '0']\n",
      "['69.57', '48', '51636.92', '113.12', 'Centralized content-based focus group', 'West Katiefurt', '1', 'Egypt', '6/3/2016 1:14', '1']\n",
      "['79.52', '24', '51739.63', '214.23', 'Synergistic fresh-thinking array', 'North Tara', '0', 'Bosnia and Herzegovina', '4/20/2016 21:49', '0']\n",
      "['42.95', '33', '30976', '143.56', 'Grass-roots coherent extranet', 'West William', '0', 'Barbados', '3/24/2016 9:31', '1']\n",
      "['63.45', '23', '52182.23', '140.64', 'Persistent demand-driven interface', 'New Travistown', '1', 'Spain', '3/9/2016 3:41', '1']\n",
      "['55.39', '37', '23936.86', '129.41', 'Customizable multi-tasking website', 'West Dylanberg', '0', 'Palestinian Territory', '1/30/2016 19:20', '1']\n",
      "['82.03', '41', '71511.08', '187.53', 'Intuitive dynamic attitude', 'Pruittmouth', '0', 'Afghanistan', '5/2/2016 7:00', '0']\n",
      "['54.7', '36', '31087.54', '118.39', 'Grass-roots solution-oriented conglomeration', 'Jessicastad', '1', 'British Indian Ocean Territory (Chagos Archipelago)', '2/13/2016 7:53', '1']\n"
     ]
    }
   ],
   "source": [
    "with open('Data_Files/adsmall.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file,delimiter=',',quotechar='\"')\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = ['TimeSpent','Age','AreaIncome','DailyInternetUsage','AdHeadLine','City','Male','Country','Timestamp','Clicked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 year olds spends 68.95 minutes on the internet before clicking on an Ad.\n",
      "31 year olds spends 80.23 minutes on the internet before clicking on an Ad.\n",
      "26 year olds spends 69.47 minutes on the internet before clicking on an Ad.\n",
      "29 year olds spends 74.15 minutes on the internet before clicking on an Ad.\n",
      "35 year olds spends 68.37 minutes on the internet before clicking on an Ad.\n",
      "23 year olds spends 59.99 minutes on the internet before clicking on an Ad.\n",
      "33 year olds spends 88.91 minutes on the internet before clicking on an Ad.\n",
      "48 year olds spends 66 minutes on the internet before clicking on an Ad.\n",
      "30 year olds spends 74.53 minutes on the internet before clicking on an Ad.\n",
      "20 year olds spends 69.88 minutes on the internet before clicking on an Ad.\n",
      "49 year olds spends 47.64 minutes on the internet before clicking on an Ad.\n",
      "37 year olds spends 83.07 minutes on the internet before clicking on an Ad.\n",
      "48 year olds spends 69.57 minutes on the internet before clicking on an Ad.\n",
      "24 year olds spends 79.52 minutes on the internet before clicking on an Ad.\n",
      "33 year olds spends 42.95 minutes on the internet before clicking on an Ad.\n",
      "23 year olds spends 63.45 minutes on the internet before clicking on an Ad.\n",
      "37 year olds spends 55.39 minutes on the internet before clicking on an Ad.\n",
      "41 year olds spends 82.03 minutes on the internet before clicking on an Ad.\n",
      "36 year olds spends 54.7 minutes on the internet before clicking on an Ad.\n"
     ]
    }
   ],
   "source": [
    "#Reading with \"DictReader\" function\n",
    "with open('Data_Files/adsmall.csv') as csv_file:\n",
    "    csv_dict_reader = csv.DictReader(csv_file,fieldnames=field_names)\n",
    "    for row in csv_dict_reader:\n",
    "        print(row['Age'] + ' year olds spends ' + row['TimeSpent'] + ' minutes on the internet before clicking on an Ad.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to \"Quote Minimals\" to your csv source files if there is an additional comma inputted as a single field value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV from URL schemes (http, ftp, etc)\n",
    "import pandas as pd\n",
    "\n",
    "remote_file = 'https://raw.githubusercontent.com/genelee9-vc/python/master/GA_COVID.csv'\n",
    "#Below if GitHub repo is not public\n",
    "#'https://raw.githubusercontent.com/genelee9-vc/python/master/GA_COVID.csv?token=AMWQI4RR3PZDVRCYP7XBSZC6X5COU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date</td>\n",
       "      <td>state</td>\n",
       "      <td>positive</td>\n",
       "      <td>death</td>\n",
       "      <td>hospitalized</td>\n",
       "      <td>deathIncrease</td>\n",
       "      <td>hospitalizedIncrease</td>\n",
       "      <td>positiveIncrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>27270</td>\n",
       "      <td>1154</td>\n",
       "      <td>5269</td>\n",
       "      <td>34</td>\n",
       "      <td>113</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>26155</td>\n",
       "      <td>1120</td>\n",
       "      <td>5156</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>25572</td>\n",
       "      <td>1093</td>\n",
       "      <td>5056</td>\n",
       "      <td>67</td>\n",
       "      <td>242</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>24615</td>\n",
       "      <td>1026</td>\n",
       "      <td>4814</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1          2       3              4               5  \\\n",
       "0       Date  state   positive   death   hospitalized   deathIncrease   \n",
       "1   5/1/2020     GA      27270    1154           5269              34   \n",
       "2  4/30/2020     GA      26155    1120           5156              27   \n",
       "3  4/29/2020     GA      25572    1093           5056              67   \n",
       "4  4/28/2020     GA      24615    1026           4814              55   \n",
       "\n",
       "                       6                  7  \n",
       "0   hospitalizedIncrease   positiveIncrease  \n",
       "1                    113               1115  \n",
       "2                    100                583  \n",
       "3                    242                957  \n",
       "4                    133                702  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_url = pd.read_csv(remote_file,header=None)\n",
    "\n",
    "posts_url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>27270</td>\n",
       "      <td>1154</td>\n",
       "      <td>5269</td>\n",
       "      <td>34</td>\n",
       "      <td>113</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>26155</td>\n",
       "      <td>1120</td>\n",
       "      <td>5156</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>25572</td>\n",
       "      <td>1093</td>\n",
       "      <td>5056</td>\n",
       "      <td>67</td>\n",
       "      <td>242</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>24615</td>\n",
       "      <td>1026</td>\n",
       "      <td>4814</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>23913</td>\n",
       "      <td>971</td>\n",
       "      <td>4681</td>\n",
       "      <td>59</td>\n",
       "      <td>322</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/26/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>23401</td>\n",
       "      <td>912</td>\n",
       "      <td>4359</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4/25/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>22695</td>\n",
       "      <td>904</td>\n",
       "      <td>4326</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4/24/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>22147</td>\n",
       "      <td>892</td>\n",
       "      <td>4221</td>\n",
       "      <td>20</td>\n",
       "      <td>152</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date state   positive   death   hospitalized   deathIncrease  \\\n",
       "0   5/1/2020    GA      27270    1154           5269              34   \n",
       "1  4/30/2020    GA      26155    1120           5156              27   \n",
       "2  4/29/2020    GA      25572    1093           5056              67   \n",
       "3  4/28/2020    GA      24615    1026           4814              55   \n",
       "4  4/27/2020    GA      23913     971           4681              59   \n",
       "5  4/26/2020    GA      23401     912           4359               8   \n",
       "6  4/25/2020    GA      22695     904           4326              12   \n",
       "7  4/24/2020    GA      22147     892           4221              20   \n",
       "\n",
       "    hospitalizedIncrease   positiveIncrease  \n",
       "0                    113               1115  \n",
       "1                    100                583  \n",
       "2                    242                957  \n",
       "3                    133                702  \n",
       "4                    322                512  \n",
       "5                     33                706  \n",
       "6                    105                548  \n",
       "7                    152                635  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To specify the exact number of rows you want to read\n",
    "posts_small = pd.read_csv(remote_file,nrows=8)\n",
    "posts_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4/27/2020</th>\n",
       "      <th>GA</th>\n",
       "      <th>23913</th>\n",
       "      <th>971</th>\n",
       "      <th>4681</th>\n",
       "      <th>59</th>\n",
       "      <th>322</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/26/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>23401</td>\n",
       "      <td>912</td>\n",
       "      <td>4359</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/25/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>22695</td>\n",
       "      <td>904</td>\n",
       "      <td>4326</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/24/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>22147</td>\n",
       "      <td>892</td>\n",
       "      <td>4221</td>\n",
       "      <td>20</td>\n",
       "      <td>152</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/23/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>21512</td>\n",
       "      <td>872</td>\n",
       "      <td>4069</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/22/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>20740</td>\n",
       "      <td>836</td>\n",
       "      <td>3959</td>\n",
       "      <td>37</td>\n",
       "      <td>180</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/21/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>19881</td>\n",
       "      <td>799</td>\n",
       "      <td>3779</td>\n",
       "      <td>66</td>\n",
       "      <td>229</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4/20/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>18947</td>\n",
       "      <td>733</td>\n",
       "      <td>3550</td>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4/19/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>18301</td>\n",
       "      <td>687</td>\n",
       "      <td>3464</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/18/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>17669</td>\n",
       "      <td>673</td>\n",
       "      <td>3420</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/17/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>17194</td>\n",
       "      <td>650</td>\n",
       "      <td>3324</td>\n",
       "      <td>63</td>\n",
       "      <td>216</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4/27/2020  GA  23913  971  4681  59  322   512\n",
       "0  4/26/2020  GA  23401  912  4359   8   33   706\n",
       "1  4/25/2020  GA  22695  904  4326  12  105   548\n",
       "2  4/24/2020  GA  22147  892  4221  20  152   635\n",
       "3  4/23/2020  GA  21512  872  4069  36  110   772\n",
       "4  4/22/2020  GA  20740  836  3959  37  180   859\n",
       "5  4/21/2020  GA  19881  799  3779  66  229   934\n",
       "6  4/20/2020  GA  18947  733  3550  46   86   646\n",
       "7  4/19/2020  GA  18301  687  3464  14   44   632\n",
       "8  4/18/2020  GA  17669  673  3420  23   96   475\n",
       "9  4/17/2020  GA  17194  650  3324  63  216  1525"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To specify the exact number of rows to skip that you want to read\n",
    "posts_small_skiprows = pd.read_csv(remote_file,nrows=10,skiprows=5)\n",
    "posts_small_skiprows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, the code skips the first 5 lines of data and starts index 0,1,2 etc at the 6th line in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>26155</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>5156.0</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>24615</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>55</td>\n",
       "      <td>133</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/26/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>23401</td>\n",
       "      <td>912.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/24/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>22147</td>\n",
       "      <td>892.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>20</td>\n",
       "      <td>152</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/22/2020</td>\n",
       "      <td>GA</td>\n",
       "      <td>20740</td>\n",
       "      <td>836.0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>37</td>\n",
       "      <td>180</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date state   positive   death   hospitalized   deathIncrease  \\\n",
       "0  4/30/2020    GA      26155  1120.0         5156.0              27   \n",
       "1  4/28/2020    GA      24615  1026.0         4814.0              55   \n",
       "2  4/26/2020    GA      23401   912.0         4359.0               8   \n",
       "3  4/24/2020    GA      22147   892.0         4221.0              20   \n",
       "4  4/22/2020    GA      20740   836.0         3959.0              37   \n",
       "\n",
       "    hospitalizedIncrease   positiveIncrease  \n",
       "0                    100                583  \n",
       "1                    133                702  \n",
       "2                     33                706  \n",
       "3                    152                635  \n",
       "4                    180                859  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to just pull in odd rows, use \"LAMBDA\" calculus feature in Python\n",
    "posts_odd = pd.read_csv(remote_file,skiprows=lambda x: x % 2 !=0)\n",
    "posts_odd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>death</th>\n",
       "      <th>deathIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2020</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2020</td>\n",
       "      <td>971.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   death   deathIncrease\n",
       "0   5/1/2020  1154.0            34.0\n",
       "1  4/30/2020  1120.0            27.0\n",
       "2  4/29/2020  1093.0            67.0\n",
       "3  4/28/2020  1026.0            55.0\n",
       "4  4/27/2020   971.0            59.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_columns = pd.read_csv(remote_file,usecols=[0,3,5])\n",
    "posts_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-45dd38977c41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# To understand the datatype of your files on specific columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mremote_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "# Can't run this on a csv file that you did not create in this app\n",
    "remote_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                      object\n",
       "state                     object\n",
       " positive                  int64\n",
       " hospitalized            float64\n",
       " hospitalizedIncrease    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To understand the datatype of your files on specific columns\n",
    "pd.read_csv(remote_file,usecols=[0,1,2,4,6]).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                     4/30/2020\n",
       "state                           GA\n",
       " positive                    26155\n",
       " hospitalized                 5156\n",
       " hospitalizedIncrease          100\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_tags=pd.read_csv(remote_file,usecols=[0,1,2,4,6])\n",
    "posts_tags.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
